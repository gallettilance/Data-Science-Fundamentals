{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 17\n",
    "\n",
    "Name:  ShanshangZeng\n",
    "UID: U87820096\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Recommender Systems\n",
    "\n",
    "### Recommender Systems\n",
    "\n",
    "In the example in class of recommending movies to users we used the movie rating as a measure of similarity between users and movies and thus the predicted rating for a user is a proxy for how highly a movie should be recommended. So the higher the predicted rating for a user, the higher a recommendation it would be.\n",
    "\n",
    "a) Consider a streaming platform that only has \"like\" or \"dislike\" (no 1-5 rating). Describe how you would build a recommender system in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "could use collaborative filtering, content-based filtering, or deep learning models to predict user preferences and recommend items based on similarities in user behavior or item characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe 3 challenges of building a recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a recommender system presents challenges such as scalability to manage large data volumes, the cold start problem for new users or items with limited data, and data sparsity with too few interactions to make reliable predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Why is SVD not an option for collaborative filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD is not ideal for collaborative filtering because it requires a complete matrix and cannot handle the typical sparsity found in user-item interaction data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Use the code below to train a recommender system on a dataset of amazon movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Initialize Spark session with required resources\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Movie Recommender\") \\\n",
    "    .config(\"spark.executor.memory\", \"28g\") \\\n",
    "    .config(\"spark.driver.memory\", \"28g\") \\\n",
    "    .config(\"spark.driver.cores\", \"8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "init_df = pd.read_csv(\"./train.csv\").dropna()\n",
    "init_df['UserId_fact'] = init_df['UserId'].astype('category').cat.codes\n",
    "init_df['ProductId_fact'] = init_df['ProductId'].astype('category').cat.codes\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train_processed, X_test_processed, Y_train, Y_test = train_test_split(\n",
    "    init_df[['UserId_fact', 'ProductId_fact']],  # directly use only needed columns\n",
    "    init_df['Score'],\n",
    "    test_size=0.25,\n",
    "    random_state=0\n",
    ")\n",
    "X_train_processed['Score'] = Y_train\n",
    "\n",
    "# Convert the pandas DataFrame to Spark DataFrame\n",
    "train_df = spark.createDataFrame(X_train_processed)\n",
    "\n",
    "# Configure the ALS model\n",
    "als = ALS(\n",
    "    userCol=\"UserId_fact\",\n",
    "    itemCol=\"ProductId_fact\",\n",
    "    ratingCol=\"Score\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=True,\n",
    "    rank=100,\n",
    "    maxIter=10,\n",
    "    regParam=0.1\n",
    ")\n",
    "\n",
    "# Fit the ALS model\n",
    "model = als.fit(train_df)\n",
    "\n",
    "# Prepare test data and make predictions\n",
    "test_df = spark.createDataFrame(X_test_processed[['UserId_fact', 'ProductId_fact']])\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Score\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Square Error = \" + str(rmse))\n",
    "\n",
    "# Optional: Save the model for later use\n",
    "# model.save(\"model_path\")\n",
    "\n",
    "# Prepare data for confusion matrix visualization\n",
    "predictions_pandas = predictions.toPandas()\n",
    "predictions_pandas['Score'] = Y_test.values\n",
    "\n",
    "# Compute and plot the confusion matrix\n",
    "cm = confusion_matrix(predictions_pandas['Score'], predictions_pandas['prediction'].round(), normalize='true')\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.title('Confusion Matrix of the Recommender System')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
